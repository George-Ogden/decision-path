{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "\n",
    "from IPython.display import Image, display\n",
    "from typing import Union\n",
    "\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams['figure.figsize'] = (20, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"ResnetV2_50.pb\" # download from https://github.com/tensorflow/models/tree/master/research/slim#Pretrained\n",
    "class_id = 988 # goldfish (classes are 1-indexed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the graph from the .pb file\n",
    "with tf.io.gfile.GFile(model_path, 'rb') as f:\n",
    "    graph_def = tf.compat.v1.GraphDef()\n",
    "    graph_def.ParseFromString(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.compat.v1.Session() as sess:\n",
    "    # Set the graph as the default graph\n",
    "    tf.compat.v1.import_graph_def(graph_def, name='')\n",
    "    graph = sess.graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tensor(tensor_name: str) -> np.ndarray:\n",
    "    with tf.compat.v1.Session() as sess:\n",
    "        # Set the graph as the default graph\n",
    "        tf.compat.v1.import_graph_def(graph_def, name='')\n",
    "\n",
    "        # Get input and output tensors\n",
    "        input_tensor = sess.graph.get_tensor_by_name(\"input:0\")\n",
    "        output_tensor = sess.graph.get_tensor_by_name(tensor_name)\n",
    "\n",
    "        # Perform inference\n",
    "        input_data = np.random.randn(1, 224, 224, 3)\n",
    "        return sess.run(output_tensor, feed_dict={input_tensor: input_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images(tensor_name: str, feature_id: int) -> Image:\n",
    "    \"\"\"download the images from OpenAI Microscope so they can be displayd in the notebook\"\"\"\n",
    "    return Image(url=f\"https://openaipublic.blob.core.windows.net/microscopeprod/2020-07-25/2020-07-25/resnetv2_50_slim/lucid.dataset_examples/_dataset_examples/dataset%3Dimagenet%26op%3D{tensor_name.replace('/', '%252F')}%253A0/channel_{feature_id}_40.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_op(tensor: Union[tf.Tensor, tf.Operation]) -> tf.Operation:\n",
    "    \"\"\"utility to convert a tensor to an operation\"\"\"\n",
    "    if isinstance(tensor, tf.Tensor):\n",
    "        return tensor.op\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def go_backwards(layer: Union[tf.Operation, str], num_layers: int=1) -> tf.Tensor:\n",
    "    \"\"\"move backwards in the graph by num_layers, always selecting the first input\"\"\"\n",
    "    if isinstance(layer, str):\n",
    "        layer = graph.get_operation_by_name(layer)\n",
    "    previous_layer = layer\n",
    "    for _ in range(num_layers):\n",
    "        previous_layer = list(to_op(previous_layer).inputs)[0]\n",
    "        print(previous_layer)\n",
    "    return to_op(previous_layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualise the final few operations\n",
    "graph.get_operations()[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the linear layer by traversing from the end\n",
    "output = graph.get_operations()[-1]\n",
    "linear_layer = go_backwards(output, 5)\n",
    "linear_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weirdly the model has 1001 classes - the usual ImageNet classes but with 1-based indexing.  \n",
    "Also, the final Conv2D is dense layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(linear_layer.inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_matrix = get_tensor(linear_layer.inputs[1].name)\n",
    "weight_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check all the weights that are relevant to the class\n",
    "relevant_weights = weight_matrix[0, 0, :, class_id]\n",
    "ordering = (-relevant_weights).argsort()\n",
    "relevant_weights.min(), relevant_weights.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a histogram of the distribution of the weights\n",
    "sns.histplot(relevant_weights, bins=100)\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most weights are close to zero, but there are a few that are much larger.  \n",
    "Large negative weights are very rare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the features related to the largest weights\n",
    "important_features = ordering[:5]\n",
    "important_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the relevant values\n",
    "relevant_weights[important_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the main feature to visualise\n",
    "main_feature = important_features[0]\n",
    "main_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backtrack to the residual stream\n",
    "residual_stream = go_backwards(linear_layer, 4)\n",
    "residual_stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset examples that maximise the last feature activation\n",
    "display(get_images(residual_stream.name, main_feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go back in the residual stream\n",
    "residual_stream = go_backwards(residual_stream)\n",
    "residual_stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the dataset examples that maximise the feature activation\n",
    "display(get_images(residual_stream.name, main_feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go back in the residual stream\n",
    "residual_stream = go_backwards(residual_stream)\n",
    "residual_stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the dataset examples that maximise the feature activation\n",
    "display(get_images(residual_stream.name, main_feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the shortcut\n",
    "shortcut = go_backwards(residual_stream, 2)\n",
    "weights = get_tensor(shortcut.inputs[1].name)\n",
    "weights.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The residual stream changes shape here so the shortcut is a matrix to map from the previous shape to the new one.  \n",
    "These connections seem to matter less than the simple add that happens between most layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot distribution of weights going into the main feature\n",
    "feature_weights = weights[0, 0, :, main_feature]\n",
    "sns.histplot(feature_weights, bins=100)\n",
    "main_feature = feature_weights.argmax()\n",
    "main_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the dataset examples that maximise the feature going backwards in the network\n",
    "residual_stream = shortcut\n",
    "for _ in range(6):\n",
    "    residual_stream = go_backwards(residual_stream)\n",
    "    while not residual_stream.name.endswith(\"add\"):\n",
    "        residual_stream = go_backwards(residual_stream)\n",
    "    display(get_images(residual_stream.name, main_feature))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These generally seem to be less relevant to the class, suggesting there is an important change between these two layers."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
